# Reading
In this set of exercises, there is a lot of reading. The main reference is a review paper called [Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers](http://stanford.edu/~boyd/papers/admm_distr_stats.html), by Boyd et al. This is a truly excellent review paper and a popular one, as its citation count on Google Scholar reveals. For this set of exercises, I have read Sections 1-6 of the paper.

For basic concepts in convex optimization used in this paper, some useful background material on Lagrangians and duality can be found in Chapter 5 (and for background, 3.3) of [Convex Optimization](http://stanford.edu/~boyd/cvxbook/), by Boyd and Vandeberghe (see the Download link at the bottom of this linked page).

# Exercises
The assignment is simple: implement ADMM for fitting the lasso regression model, and compare it to the proximal gradient implementation from exercise06. The application of ADMM to the lasso model is described in Section 6.4 of the Boyd et. al. paper.

# Output of R Code
http://rpubs.com/leexiner/bigdata-exercise07
